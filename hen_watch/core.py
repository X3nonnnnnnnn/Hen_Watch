from __future__ import annotations
import hashlib
import os
import re
from dataclasses import dataclass
from typing import List, Dict, Optional
from urllib.parse import quote, urljoin
import html as html_lib

import requests
from bs4 import BeautifulSoup

from .storage import read_state, write_state

EH_BASE = "https://e-hentai.org/?f_search="


@dataclass
class Config:
    search_url: str
    authors: List[str]
    result_selector: str
    title_selector: str
    link_selector: str
    telegram_enabled: bool
    telegram_bot_token: str
    telegram_chat_id: str


def _pick_env(name: str, default: Optional[str] = None) -> Optional[str]:
    v = os.getenv(name)
    return v if v is not None else default


def load_config(cfg_path: str = "config.toml") -> Config:
    try:
        import tomllib as toml
    except Exception:
        import tomli as toml  # type: ignore

    data: Dict = {}
    if os.path.exists(cfg_path):
        with open(cfg_path, "rb") as f:
            data = toml.load(f)

    tg = data.get("telegram", {}) or {}
    cfg = Config(
        search_url=str(data.get("search_url", "") or ""),
        authors=list(data.get("authors", []) or []),
        result_selector=str(data.get("result_selector", "") or ""),
        title_selector=str(data.get("title_selector", "") or ""),
        link_selector=str(data.get("link_selector", "") or ""),
        telegram_enabled=bool(tg.get("enabled", False)),
        telegram_bot_token=str(tg.get("bot_token", "") or ""),
        telegram_chat_id=str(tg.get("chat_id", "") or ""),
    )

    # ç¯å¢ƒå˜é‡è¦†ç›–
    authors_env = _pick_env("SEARCH_AUTHORS")
    if authors_env:
        parts = re.split(r"[,ï¼Œã€\n\r]+", authors_env)
        cfg.authors = [p.strip() for p in parts if p.strip()]

    surl = _pick_env("SEARCH_URL")
    if surl:
        cfg.search_url = surl

    for key, env_name in [
        ("result_selector", "RESULT_SELECTOR"),
        ("title_selector", "TITLE_SELECTOR"),
        ("link_selector", "LINK_SELECTOR"),
    ]:
        val = _pick_env(env_name)
        if val is not None:
            setattr(cfg, key, val)

    tge = _pick_env("TELEGRAM_ENABLED")
    if tge is not None:
        cfg.telegram_enabled = tge.lower() in ("1", "true", "yes", "on")

    for key, env_name in [
        ("telegram_bot_token", "TELEGRAM_BOT_TOKEN"),
        ("telegram_chat_id", "TELEGRAM_CHAT_ID"),
    ]:
        val = _pick_env(env_name)
        if val is not None:
            setattr(cfg, key, val)

    if not cfg.authors and not cfg.search_url:
        raise ValueError("å¿…é¡»æä¾› SEARCH_AUTHORSï¼ˆå¤šä½œè€…ï¼‰æˆ– SEARCH_URLï¼ˆå•ä½œè€…ï¼‰ã€‚")

    return cfg


DEFAULT_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/129.0 Safari/537.36"
    ),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.9",
    "Cache-Control": "no-cache",
}


def _http_get(url: str, timeout: int = 30) -> str:
    r = requests.get(url, headers=DEFAULT_HEADERS, timeout=timeout)
    r.raise_for_status()
    return r.text


def _text(s: str) -> str:
    return re.sub(r"\s+", " ", s).strip()


def _checksum(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    for t in soup(["script", "style"]):
        t.extract()
    return hashlib.sha256(_text(soup.get_text(" ")).encode("utf-8")).hexdigest()


# ===== åŸºäºä½ ç»™çš„æ€è·¯ï¼šä»ç»“æœå¡ç‰‡ä¸Šâ€œå¯é æå–ç¼©ç•¥å›¾â€ =====

def _abs_url(base: str, src: str) -> str:
    """æŠŠ // æˆ– / æˆ–ç›¸å¯¹è·¯å¾„è¡¥æˆç»å¯¹ URL"""
    if not src:
        return ""
    s = html_lib.unescape(src.strip())
    if s.startswith("//"):
        return "https:" + s
    return urljoin(base, s)

def _pick_from_img_tag(img) -> Optional[str]:
    """æŒ‰ä¼˜å…ˆçº§ä» <img> æå–çœŸå®åœ°å€ï¼šdata-* â†’ srcset(æœ€å¤§) â†’ src â†’ noscript å†…çš„çœŸå® <img>"""
    # 1) å¸¸è§æ‡’åŠ è½½å±æ€§
    for key in ("data-src", "data-lazy", "data-original"):
        v = img.get(key)
        if v:
            return v
    # 2) srcsetï¼ˆå–æœ€åä¸€é¡¹é€šå¸¸åˆ†è¾¨ç‡æœ€é«˜ï¼‰
    ss = img.get("srcset")
    if ss:
        parts = [p.strip().split(" ")[0] for p in ss.split(",") if p.strip()]
        if parts:
            return parts[-1] or parts[0]
    # 3) å¸¸è§„ srcï¼ˆæ’é™¤ data: å ä½ï¼‰
    s = img.get("src")
    if s and not s.startswith("data:"):
        return s
    # 4) å°±è¿‘çš„ <noscript> é‡Œå†æ‰¾ä¸€æ¬¡çœŸå® <img>
    ns = None
    cur = img
    for _ in range(3):
        if not cur:
            break
        ns = cur.find_next_sibling("noscript") or cur.find("noscript")
        if ns:
            break
        cur = cur.parent
    if ns and ns.string:
        ns_soup = BeautifulSoup(ns.string, "html.parser")
        real_img = ns_soup.find("img")
        if real_img:
            return real_img.get("data-src") or real_img.get("src")
    return None

def _pick_from_style(el) -> Optional[str]:
    """ä» style='background-image:url(...)' ä¸­æå– URL"""
    style = el.get("style") or ""
    m = re.search(r"url\((['\"]?)(.*?)\1\)", style, flags=re.I)
    return m.group(2) if m else None

def _cover_from_result_node(node, page_base: str) -> str:
    """
    ä»æœç´¢ç»“æœçš„â€œå¡ç‰‡èŠ‚ç‚¹â€ä¸Šå°½å¯èƒ½å–åˆ°ç¼©ç•¥å›¾ï¼š
    - å…ˆæ‰¾ imgï¼šdata-src/srcset/src â†’ noscript
    - å†æ‰¾ div èƒŒæ™¯å›¾ style â†’ noscript
    """
    # ä¼˜å…ˆå¡ç‰‡å†…éƒ¨çš„æ‰€æœ‰ img
    for img in node.select("img"):
        u = _pick_from_img_tag(img)
        if u and not u.startswith("data:"):
            return _abs_url(page_base, u)

    # å…¶æ¬¡ï¼šdiv èƒŒæ™¯å›¾ æˆ– noscript å†…åµŒ
    for el in node.select("div"):
        u = _pick_from_style(el)
        if u:
            return _abs_url(page_base, u)
        ns = el.find("noscript")
        if ns and ns.string:
            ns_soup = BeautifulSoup(ns.string, "html.parser")
            real_img = ns_soup.find("img")
            if real_img:
                u2 = real_img.get("data-src") or real_img.get("src")
                if u2:
                    return _abs_url(page_base, u2)

    return ""


def _extract_items(html: str, cfg: Config) -> List[Dict[str, str]]:
    soup = BeautifulSoup(html, "html.parser")
    if not cfg.result_selector:
        return [{"id": "PAGE", "title": "Full page", "url": "", "cover": ""}]

    page_base = "https://e-hentai.org"
    items: List[Dict[str, str]] = []
    for node in soup.select(cfg.result_selector):
        # æ‰¾åˆ°å¡ç‰‡ä¸Šçš„ç”»å»Šé“¾æ¥
        if getattr(node, "name", None) == "a" and node.has_attr("href"):
            anchor = node
        else:
            anchor = node.select_one("a[href*='/g/']")
        if not anchor or not anchor.has_attr("href") or "/g/" not in anchor["href"]:
            continue

        # æ ‡é¢˜
        title = ""
        if cfg.title_selector.strip():
            tnode = node.select_one(cfg.title_selector)
            if tnode:
                title = _text(tnode.get_text(" "))
        if not title:
            title = _text(anchor.get_text(" "))

        # URLï¼ˆè¡¥å…¨æˆç»å¯¹ï¼‰
        url = ""
        if cfg.link_selector.strip():
            lnode = node.select_one(cfg.link_selector)
            if lnode is not None and lnode.has_attr("href"):
                url = lnode["href"]
        if not url:
            url = anchor["href"]
        url = _abs_url(page_base, url)

        # å°é¢ï¼ˆä½¿ç”¨æ–°çš„â€œç»“æœå¡ç‰‡æå–ç­–ç•¥â€ï¼‰
        cover = _cover_from_result_node(node, page_base)

        # ç”Ÿæˆæ¡ç›®
        ident_src = url or title
        ident = hashlib.sha1(ident_src.encode("utf-8")).hexdigest()[:16]
        items.append({
            "id": ident,
            "title": title or "(no title)",
            "url": url,
            "cover": cover,
        })

    # å»é‡
    uniq, seen = [], set()
    for it in items:
        if it["id"] not in seen:
            seen.add(it["id"])
            uniq.append(it)
    return uniq


def _author_url(name: str) -> str:
    return f"{EH_BASE}{quote(name.strip())}"


def _fetch_for_author(author: str, cfg: Config):
    url = _author_url(author)
    html = _http_get(url)
    return url, _extract_items(html, cfg), _checksum(html)


def _diff(prev_items: Dict[str, Dict[str, str]], new_items: List[Dict[str, str]]):
    old_ids = set(prev_items.keys())
    new_ids = {it["id"] for it in new_items}
    added_ids = new_ids - old_ids
    removed_ids = old_ids - new_ids
    added = [it for it in new_items if it["id"] in added_ids]
    removed = [prev_items[i] for i in removed_ids]
    return added, removed


def _send_text(token: str, chat: str, text: str) -> None:
    if not token or not chat:
        return
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    r = requests.post(url, json={"chat_id": chat, "text": text, "disable_web_page_preview": True}, timeout=30)
    if r.status_code != 200:
        try:
            print("TELEGRAM_SEND_ERROR:", r.status_code, r.text[:300])
        except Exception:
            pass


def run_once(cfg_path: str = "config.toml") -> int:
    cfg = load_config(cfg_path)
    state = read_state()
    authors = [a for a in cfg.authors if a.strip()]
    single_mode = not authors

    if "authors" not in state:
        state["authors"] = {}

    # æ˜¯å¦é¦–æ¬¡ï¼ˆä»“åº“çº§ï¼‰
    is_initial_repo_run = (len(state["authors"]) == 0) and single_mode is False
    added_by_author: Dict[str, List[Dict[str, str]]] = {}
    new_author_baselined: List[str] = []
    processed_existing_authors = 0

    if authors:
        for name in authors:
            url, items, checksum = _fetch_for_author(name, cfg)
            prev = state["authors"].get(name, {})
            prev_items_dict = {it["id"]: it for it in prev.get("items", [])}

            if not prev:
                # æ–°ä½œè€…é™é»˜å»ºåŸºçº¿
                new_author_baselined.append(name)
                state["authors"][name] = {"checksum": checksum, "items": items}
                continue

            processed_existing_authors += 1
            added, _ = _diff(prev_items_dict, items)
            if added:
                added_by_author[name] = added

            state["authors"][name] = {"checksum": checksum, "items": items}
    else:
        # å• URL æ¨¡å¼
        html_url = cfg.search_url
        html = _http_get(html_url)
        checksum = _checksum(html)
        items = _extract_items(html, cfg)
        prev = state.get("single", {})
        prev_items_dict = {it["id"]: it for it in prev.get("items", [])}
        if not prev:
            state["single"] = {"checksum": checksum, "items": items}
            write_state(state)
            print("First run (single URL): baseline saved. No notification.")
            return 0
        else:
            added, _ = _diff(prev_items_dict, items)
            if added:
                added_by_author[html_url] = added
            state["single"] = {"checksum": checksum, "items": items}

    # é¦–æ¬¡ä»“åº“å»ºåŸºçº¿ï¼šä¸é€šçŸ¥
    if single_mode is False:
        if is_initial_repo_run and processed_existing_authors == 0:
            write_state(state)
            print("First run (repo): baseline saved for all authors. No notification.")
            return 0

    # æœ‰æ–°å¢åˆ™å‘æ–°å¢ï¼›å¦åˆ™å‘ â€œå…¨éƒ½æ²¡æ›´æ–°â€
    if cfg.telegram_enabled:
        if added_by_author:
            lines = ["ğŸ•’ æœ¬æ¬¡å·¡æ£€ç»“æœï¼ˆä»…å±•ç¤ºæ–°å¢ï¼‰ï¼š"]
            for a, items in added_by_author.items():
                # ç›´æ¥å‘è£¸é“¾æ¥ï¼Œé¿å… Telegram äºŒæ¬¡ç¡®è®¤å¼¹çª—
                lines.append(f"{a}: æ–°å¢ {len(items)} æ¡ {_author_url(a)}")
            summary = "\n".join(lines)

            if len(summary) <= 4000:
                _send_text(cfg.telegram_bot_token, cfg.telegram_chat_id, summary)
            else:
                msg = summary
                while msg:
                    chunk = msg[:4000]
                    cut = chunk.rfind("\n")
                    if 0 < cut < 4000:
                        to_send, msg = chunk[:cut], msg[cut+1:]
                    else:
                        to_send, msg = chunk, msg[4000:]
                    _send_text(cfg.telegram_bot_token, cfg.telegram_chat_id, to_send)
        else:
            _send_text(cfg.telegram_bot_token, cfg.telegram_chat_id, "å…¨éƒ½æ²¡æ›´æ–°")

    write_state(state)
    return 0
